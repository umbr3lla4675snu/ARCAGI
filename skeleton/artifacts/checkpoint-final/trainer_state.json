{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2,
  "eval_steps": 250,
  "global_step": 750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 632.688232421875,
      "learning_rate": 3.2e-06,
      "loss": 30.2987,
      "step": 10
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 258.83966064453125,
      "learning_rate": 7.99967558349561e-06,
      "loss": 22.3718,
      "step": 20
    },
    {
      "epoch": 0.008,
      "grad_norm": 48.45692443847656,
      "learning_rate": 7.993909642772684e-06,
      "loss": 14.1627,
      "step": 30
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 25.8765926361084,
      "learning_rate": 7.980946406922586e-06,
      "loss": 10.8145,
      "step": 40
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 23.38199806213379,
      "learning_rate": 7.960809236572509e-06,
      "loss": 9.8731,
      "step": 50
    },
    {
      "epoch": 0.016,
      "grad_norm": 24.0665225982666,
      "learning_rate": 7.933534420264507e-06,
      "loss": 7.9946,
      "step": 60
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 22.786537170410156,
      "learning_rate": 7.899171109061092e-06,
      "loss": 6.7238,
      "step": 70
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 13.957037925720215,
      "learning_rate": 7.85778122797169e-06,
      "loss": 5.5082,
      "step": 80
    },
    {
      "epoch": 0.024,
      "grad_norm": 13.433408737182617,
      "learning_rate": 7.809439364359593e-06,
      "loss": 4.7692,
      "step": 90
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 10.196707725524902,
      "learning_rate": 7.754232633530485e-06,
      "loss": 4.1089,
      "step": 100
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 10.721343040466309,
      "learning_rate": 7.69226052174478e-06,
      "loss": 4.1078,
      "step": 110
    },
    {
      "epoch": 0.032,
      "grad_norm": 8.873465538024902,
      "learning_rate": 7.62363470693665e-06,
      "loss": 4.2008,
      "step": 120
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 9.376437187194824,
      "learning_rate": 7.548478857462841e-06,
      "loss": 3.8432,
      "step": 130
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 8.939474105834961,
      "learning_rate": 7.466928409243939e-06,
      "loss": 3.8945,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.524930000305176,
      "learning_rate": 7.37913032169968e-06,
      "loss": 3.6584,
      "step": 150
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 11.726570129394531,
      "learning_rate": 7.285242812918145e-06,
      "loss": 3.9766,
      "step": 160
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 10.873689651489258,
      "learning_rate": 7.1854350745360785e-06,
      "loss": 3.6947,
      "step": 170
    },
    {
      "epoch": 0.048,
      "grad_norm": 9.891695976257324,
      "learning_rate": 7.0798869668441125e-06,
      "loss": 3.7189,
      "step": 180
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 9.029980659484863,
      "learning_rate": 6.968788694666369e-06,
      "loss": 3.7521,
      "step": 190
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 9.205714225769043,
      "learning_rate": 6.852340464598519e-06,
      "loss": 3.4834,
      "step": 200
    },
    {
      "epoch": 0.056,
      "grad_norm": 10.745803833007812,
      "learning_rate": 6.730752124221954e-06,
      "loss": 3.8861,
      "step": 210
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 9.374926567077637,
      "learning_rate": 6.604242783944265e-06,
      "loss": 3.5421,
      "step": 220
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 10.507800102233887,
      "learning_rate": 6.473040422147479e-06,
      "loss": 3.7318,
      "step": 230
    },
    {
      "epoch": 0.064,
      "grad_norm": 9.356579780578613,
      "learning_rate": 6.337381474355606e-06,
      "loss": 3.7182,
      "step": 240
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 11.648664474487305,
      "learning_rate": 6.197510407161841e-06,
      "loss": 3.5319,
      "step": 250
    },
    {
      "epoch": 0.06666666666666667,
      "eval_loss": 0.4303145110607147,
      "eval_runtime": 89.5998,
      "eval_samples_per_second": 1.116,
      "eval_steps_per_second": 1.116,
      "step": 250
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 12.574990272521973,
      "learning_rate": 6.0536792776832425e-06,
      "loss": 3.7976,
      "step": 260
    },
    {
      "epoch": 0.072,
      "grad_norm": 9.4572114944458,
      "learning_rate": 5.906147279336767e-06,
      "loss": 3.623,
      "step": 270
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 10.816998481750488,
      "learning_rate": 5.755180274755219e-06,
      "loss": 3.5261,
      "step": 280
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 10.056150436401367,
      "learning_rate": 5.601050316684808e-06,
      "loss": 3.588,
      "step": 290
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.855239868164062,
      "learning_rate": 5.444035157727721e-06,
      "loss": 3.5472,
      "step": 300
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 11.747654914855957,
      "learning_rate": 5.284417749813152e-06,
      "loss": 3.6434,
      "step": 310
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 12.252493858337402,
      "learning_rate": 5.122485734298807e-06,
      "loss": 3.3477,
      "step": 320
    },
    {
      "epoch": 0.088,
      "grad_norm": 13.303499221801758,
      "learning_rate": 4.958530923621728e-06,
      "loss": 3.5179,
      "step": 330
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 12.050541877746582,
      "learning_rate": 4.7928487754325675e-06,
      "loss": 3.4712,
      "step": 340
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 12.685282707214355,
      "learning_rate": 4.625737860160924e-06,
      "loss": 3.2998,
      "step": 350
    },
    {
      "epoch": 0.096,
      "grad_norm": 9.737883567810059,
      "learning_rate": 4.4574993229712494e-06,
      "loss": 3.5117,
      "step": 360
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 9.768260955810547,
      "learning_rate": 4.2884363410789095e-06,
      "loss": 3.6256,
      "step": 370
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 9.914085388183594,
      "learning_rate": 4.118853577404352e-06,
      "loss": 3.292,
      "step": 380
    },
    {
      "epoch": 0.104,
      "grad_norm": 15.4014310836792,
      "learning_rate": 3.949056631549919e-06,
      "loss": 3.5101,
      "step": 390
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 11.20617389678955,
      "learning_rate": 3.7793514890887295e-06,
      "loss": 3.6042,
      "step": 400
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 10.627829551696777,
      "learning_rate": 3.6100439701579752e-06,
      "loss": 3.5779,
      "step": 410
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.623448371887207,
      "learning_rate": 3.4414391783503737e-06,
      "loss": 3.4691,
      "step": 420
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 11.290263175964355,
      "learning_rate": 3.273840950896867e-06,
      "loss": 3.6946,
      "step": 430
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 12.50437068939209,
      "learning_rate": 3.107551311131394e-06,
      "loss": 3.16,
      "step": 440
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.879562377929688,
      "learning_rate": 2.942869924224441e-06,
      "loss": 3.574,
      "step": 450
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 10.727450370788574,
      "learning_rate": 2.780093557166129e-06,
      "loss": 3.4486,
      "step": 460
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 12.304312705993652,
      "learning_rate": 2.6195155439720582e-06,
      "loss": 3.6925,
      "step": 470
    },
    {
      "epoch": 0.128,
      "grad_norm": 16.070083618164062,
      "learning_rate": 2.461425257075572e-06,
      "loss": 3.2897,
      "step": 480
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 16.216598510742188,
      "learning_rate": 2.3061075858590847e-06,
      "loss": 3.8134,
      "step": 490
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 11.795469284057617,
      "learning_rate": 2.153842423264145e-06,
      "loss": 3.1879,
      "step": 500
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 0.4101385772228241,
      "eval_runtime": 89.87,
      "eval_samples_per_second": 1.113,
      "eval_steps_per_second": 1.113,
      "step": 500
    },
    {
      "epoch": 0.136,
      "grad_norm": 17.054702758789062,
      "learning_rate": 2.004904161405452e-06,
      "loss": 3.7604,
      "step": 510
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 14.059155464172363,
      "learning_rate": 1.8595611970977018e-06,
      "loss": 3.5354,
      "step": 520
    },
    {
      "epoch": 0.14133333333333334,
      "grad_norm": 10.931307792663574,
      "learning_rate": 1.7180754481864067e-06,
      "loss": 3.0933,
      "step": 530
    },
    {
      "epoch": 0.144,
      "grad_norm": 14.780577659606934,
      "learning_rate": 1.580701881554213e-06,
      "loss": 3.5997,
      "step": 540
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 10.989006996154785,
      "learning_rate": 1.4476880536533607e-06,
      "loss": 3.4627,
      "step": 550
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 12.754862785339355,
      "learning_rate": 1.3192736643922127e-06,
      "loss": 3.3475,
      "step": 560
    },
    {
      "epoch": 0.152,
      "grad_norm": 9.271821022033691,
      "learning_rate": 1.1956901251798335e-06,
      "loss": 3.4272,
      "step": 570
    },
    {
      "epoch": 0.15466666666666667,
      "grad_norm": 13.478190422058105,
      "learning_rate": 1.0771601419069698e-06,
      "loss": 3.3356,
      "step": 580
    },
    {
      "epoch": 0.15733333333333333,
      "grad_norm": 13.52431869506836,
      "learning_rate": 9.638973136149977e-07,
      "loss": 3.5357,
      "step": 590
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.642518997192383,
      "learning_rate": 8.561057475760076e-07,
      "loss": 3.4181,
      "step": 600
    },
    {
      "epoch": 0.16266666666666665,
      "grad_norm": 12.647608757019043,
      "learning_rate": 7.539796914776983e-07,
      "loss": 3.4066,
      "step": 610
    },
    {
      "epoch": 0.16533333333333333,
      "grad_norm": 14.623844146728516,
      "learning_rate": 6.577031833759292e-07,
      "loss": 3.3525,
      "step": 620
    },
    {
      "epoch": 0.168,
      "grad_norm": 16.37715721130371,
      "learning_rate": 5.674497200456865e-07,
      "loss": 3.3572,
      "step": 630
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 12.64923095703125,
      "learning_rate": 4.833819443281823e-07,
      "loss": 3.7115,
      "step": 640
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 12.739585876464844,
      "learning_rate": 4.0565135203745184e-07,
      "loss": 3.1423,
      "step": 650
    },
    {
      "epoch": 0.176,
      "grad_norm": 14.681981086730957,
      "learning_rate": 3.3439801895466647e-07,
      "loss": 3.487,
      "step": 660
    },
    {
      "epoch": 0.17866666666666667,
      "grad_norm": 13.393156051635742,
      "learning_rate": 2.6975034840209753e-07,
      "loss": 3.4481,
      "step": 670
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 13.317737579345703,
      "learning_rate": 2.11824839851658e-07,
      "loss": 3.3163,
      "step": 680
    },
    {
      "epoch": 0.184,
      "grad_norm": 14.902067184448242,
      "learning_rate": 1.6072587898497791e-07,
      "loss": 3.4567,
      "step": 690
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 11.463534355163574,
      "learning_rate": 1.1654554958335073e-07,
      "loss": 3.2961,
      "step": 700
    },
    {
      "epoch": 0.18933333333333333,
      "grad_norm": 13.28834056854248,
      "learning_rate": 7.936346758653512e-08,
      "loss": 3.4555,
      "step": 710
    },
    {
      "epoch": 0.192,
      "grad_norm": 13.148275375366211,
      "learning_rate": 4.924663761944936e-08,
      "loss": 3.3003,
      "step": 720
    },
    {
      "epoch": 0.19466666666666665,
      "grad_norm": 11.567849159240723,
      "learning_rate": 2.6249332245309452e-08,
      "loss": 3.648,
      "step": 730
    },
    {
      "epoch": 0.19733333333333333,
      "grad_norm": 11.920727729797363,
      "learning_rate": 1.0412994162802834e-08,
      "loss": 3.4868,
      "step": 740
    },
    {
      "epoch": 0.2,
      "grad_norm": 11.491497039794922,
      "learning_rate": 1.7661615235424754e-09,
      "loss": 3.1707,
      "step": 750
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.40666693449020386,
      "eval_runtime": 90.0458,
      "eval_samples_per_second": 1.111,
      "eval_steps_per_second": 1.111,
      "step": 750
    }
  ],
  "logging_steps": 10,
  "max_steps": 750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.023840009154355e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
